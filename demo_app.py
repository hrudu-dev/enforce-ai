"""EnforceAI - Demo Version (No AWS Credentials Required)"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import json
import time

# Mock data for demo
MOCK_RESOURCES = [
    {"resource_type": "EC2", "resource_id": "i-1234567890abcdef0", "encrypted": False, "region": "us-east-1"},
    {"resource_type": "RDS", "resource_id": "mydb-instance", "encrypted": True, "region": "us-east-1"},
    {"resource_type": "S3", "resource_id": "my-data-bucket", "encrypted": False, "region": "us-east-1"},
    {"resource_type": "Lambda", "resource_id": "process-data-func", "encrypted": True, "region": "us-east-1"}
]

COMPLIANCE_FRAMEWORKS = {
    "GDPR": {"name": "General Data Protection Regulation", "risk_level": "HIGH"},
    "FISMA": {"name": "Federal Information Security Management Act", "risk_level": "CRITICAL"},
    "EU_AI_ACT": {"name": "EU AI Act", "risk_level": "HIGH"},
    "ISO_42001": {"name": "ISO/IEC 42001 AI Management", "risk_level": "MEDIUM"}
}

POLICY_VIOLATIONS = [
    {"framework": "GDPR", "resource": "EC2 Instance", "violation": "Unencrypted storage", "severity": "HIGH"},
    {"framework": "FISMA", "resource": "S3 Bucket", "violation": "Public access enabled", "severity": "CRITICAL"},
    {"framework": "EU_AI_ACT", "resource": "SageMaker Model", "violation": "Missing bias testing", "severity": "HIGH"},
    {"framework": "ISO_42001", "resource": "Lambda Function", "violation": "No AI documentation", "severity": "MEDIUM"}
]

# Page config
st.set_page_config(
    page_title="EnforceAI - Demo",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

def main():
    st.title("ğŸ›¡ï¸ EnforceAI - Multi-Agent Governance Platform")
    st.markdown("*AI-powered DevOps compliance and governance automation - **DEMO VERSION***")
    
    # Sidebar
    st.sidebar.title("ğŸš€ Hackathon Demo")
    st.sidebar.markdown("**GenAI Hackathon by Impetus & AWS**")
    st.sidebar.markdown("**Category:** Multi-Agent Governance System")
    
    page = st.sidebar.selectbox("Choose Demo Section", [
        "ğŸ  Dashboard", 
        "ğŸ” Compliance Scan", 
        "âš™ï¸ Policy Engine", 
        "ğŸ¤– AI Assistant",
        "ğŸ“Š Reports"
    ])
    
    if page == "ğŸ  Dashboard":
        show_dashboard()
    elif page == "ğŸ” Compliance Scan":
        show_compliance_scan()
    elif page == "âš™ï¸ Policy Engine":
        show_policy_engine()
    elif page == "ğŸ¤– AI Assistant":
        show_ai_assistant()
    elif page == "ğŸ“Š Reports":
        show_reports()

def show_dashboard():
    st.header("ğŸ“Š Real-time Compliance Dashboard")
    
    # Key metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Overall Compliance", "75%", "â†‘ 5%")
    
    with col2:
        st.metric("Active Policies", "12", "â†‘ 2")
    
    with col3:
        st.metric("Resources Monitored", "156", "â†‘ 8")
    
    with col4:
        st.metric("Critical Violations", "3", "â†“ 2")
    
    # Charts
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Compliance Trend (30 Days)")
        dates = pd.date_range(start=datetime.now() - timedelta(days=30), end=datetime.now(), freq='D')
        scores = [70 + (i % 10) + (i // 5) for i in range(len(dates))]
        
        fig = px.line(x=dates, y=scores, title="Compliance Score Over Time")
        fig.update_layout(xaxis_title="Date", yaxis_title="Score (%)", showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("Framework Compliance")
        frameworks = list(COMPLIANCE_FRAMEWORKS.keys())
        scores = [85, 72, 68, 90]
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
        
        fig = px.bar(x=frameworks, y=scores, color=frameworks, 
                    color_discrete_sequence=colors, title="Compliance by Framework")
        fig.update_layout(xaxis_title="Framework", yaxis_title="Score (%)", showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
    
    # Violations table
    st.subheader("ğŸš¨ Recent Policy Violations")
    violations_df = pd.DataFrame(POLICY_VIOLATIONS)
    st.dataframe(violations_df, use_container_width=True)

def show_compliance_scan():
    st.header("ğŸ” Multi-Agent Compliance Scanning")
    st.markdown("*Powered by Amazon Bedrock & AWS Lambda*")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("AWS Resource Scanner")
        
        if st.button("ğŸš€ Start Multi-Agent Scan", type="primary", use_container_width=True):
            # Simulate scanning process
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Simulate agent activities
            agents = ["Audit Agent", "Compliance Agent", "Policy Agent"]
            for i, agent in enumerate(agents):
                status_text.text(f"ğŸ¤– {agent} scanning resources...")
                time.sleep(1)
                progress_bar.progress((i + 1) / len(agents))
            
            status_text.text("âœ… Multi-agent scan completed!")
            
            # Display results
            st.subheader("ğŸ“‹ Scan Results")
            results_df = pd.DataFrame(MOCK_RESOURCES)
            st.dataframe(results_df, use_container_width=True)
            
            # Compliance analysis
            st.subheader("ğŸ¯ Compliance Analysis")
            for resource in MOCK_RESOURCES:
                with st.expander(f"{resource['resource_type']} - {resource['resource_id']}"):
                    if not resource['encrypted']:
                        st.error("âŒ GDPR Violation: Encryption required for personal data")
                        st.warning("ğŸ”§ Recommended Action: Enable encryption at rest")
                    else:
                        st.success("âœ… Encryption compliance verified")
                    
                    st.info(f"ğŸ“ Region: {resource['region']}")
    
    with col2:
        st.subheader("âš™ï¸ Scan Configuration")
        
        selected_frameworks = st.multiselect(
            "Compliance Frameworks:",
            list(COMPLIANCE_FRAMEWORKS.keys()),
            default=["GDPR", "FISMA"]
        )
        
        scan_depth = st.selectbox("Scan Depth", ["Surface", "Deep", "Comprehensive"])
        auto_remediation = st.checkbox("Enable Auto-remediation", value=True)
        
        st.subheader("ğŸ¯ Agent Status")
        st.success("ğŸ¤– Audit Agent: Active")
        st.success("ğŸ¤– Compliance Agent: Active") 
        st.success("ğŸ¤– Policy Agent: Active")

def show_policy_engine():
    st.header("âš™ï¸ Dynamic Policy Engine")
    st.markdown("*AI-powered rule enforcement with Amazon Bedrock*")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ› ï¸ Policy Creation")
        
        policy_name = st.text_input("Policy Name", placeholder="e.g., GDPR Data Encryption")
        policy_framework = st.selectbox("Framework", list(COMPLIANCE_FRAMEWORKS.keys()))
        policy_severity = st.selectbox("Severity", ["LOW", "MEDIUM", "HIGH", "CRITICAL"])
        policy_description = st.text_area("Policy Description", 
                                        placeholder="Describe the compliance requirement...")
        
        if st.button("ğŸš€ Create Policy", type="primary"):
            st.success(f"âœ… Policy '{policy_name}' created for {policy_framework} framework!")
            
            # Simulate AI analysis
            with st.spinner("ğŸ¤– AI analyzing policy requirements..."):
                time.sleep(2)
            
            st.info("ğŸ§  AI Recommendation: Auto-remediation rules generated")
    
    with col2:
        st.subheader("ğŸ¯ Policy Enforcement")
        
        if st.button("âš¡ Run Policy Enforcement", use_container_width=True):
            st.markdown("**ğŸ¤– Multi-Agent Policy Enforcement Results:**")
            
            # Simulate enforcement results
            enforcement_results = [
                {"Resource": "EC2 Instance", "Policy": "GDPR Encryption", "Status": "VIOLATED", "Action": "Auto-remediated"},
                {"Resource": "S3 Bucket", "Policy": "FISMA Access Control", "Status": "COMPLIANT", "Action": "None"},
                {"Resource": "RDS Database", "Policy": "Data Retention", "Status": "VIOLATED", "Action": "Manual review"},
            ]
            
            for result in enforcement_results:
                if result["Status"] == "VIOLATED":
                    st.error(f"âŒ {result['Resource']}: {result['Policy']} - {result['Action']}")
                else:
                    st.success(f"âœ… {result['Resource']}: {result['Policy']}")
    
    # Framework details
    st.subheader("ğŸ“š Supported Compliance Frameworks")
    
    framework_tabs = st.tabs(list(COMPLIANCE_FRAMEWORKS.keys()))
    
    framework_rules = {
        "GDPR": ["Data encryption at rest", "Right to be forgotten", "Consent management", "Breach notification"],
        "FISMA": ["Multi-factor authentication", "Access controls", "Security assessments", "Incident response"],
        "EU_AI_ACT": ["AI system documentation", "Bias testing", "Human oversight", "Risk assessment"],
        "ISO_42001": ["AI governance framework", "Lifecycle management", "Risk management", "Stakeholder engagement"]
    }
    
    for i, (framework, details) in enumerate(COMPLIANCE_FRAMEWORKS.items()):
        with framework_tabs[i]:
            st.write(f"**{details['name']}**")
            st.write(f"**Risk Level:** {details['risk_level']}")
            st.write("**Key Requirements:**")
            for rule in framework_rules[framework]:
                st.write(f"â€¢ {rule}")

def show_ai_assistant():
    st.header("ğŸ¤– AI Compliance Assistant")
    st.markdown("*Powered by Amazon Bedrock (Claude)*")
    
    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "Hello! I'm your AI compliance assistant powered by Amazon Bedrock. I can help you with:\n\nâ€¢ ğŸ“‹ Policy compliance questions\nâ€¢ ğŸ” Resource scanning guidance\nâ€¢ âš™ï¸ Remediation recommendations\nâ€¢ ğŸ“Š Compliance reporting\n\nHow can I assist you today?"}
        ]
    
    # Display chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Chat input
    if prompt := st.chat_input("Ask about compliance, policies, or governance..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Generate AI response
        with st.chat_message("assistant"):
            with st.spinner("ğŸ§  AI thinking..."):
                time.sleep(1)
                
                # Simulate intelligent responses based on keywords
                response = generate_ai_response(prompt.lower())
                
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})

def generate_ai_response(prompt):
    """Generate contextual AI responses based on prompt keywords"""
    
    if "gdpr" in prompt:
        return """ğŸ›¡ï¸ **GDPR Compliance Analysis:**

Based on your AWS infrastructure scan, here are key GDPR requirements:

â€¢ **Data Encryption**: All personal data must be encrypted at rest and in transit
â€¢ **Access Controls**: Implement role-based access with audit trails  
â€¢ **Data Retention**: Define and enforce data retention policies
â€¢ **Breach Notification**: 72-hour notification requirement for data breaches

**Current Status**: 3 resources need encryption updates. Would you like me to run auto-remediation?"""
    
    elif "scan" in prompt or "audit" in prompt:
        return """ğŸ” **Multi-Agent Scanning Capabilities:**

Our AI agents can scan your AWS infrastructure for:

â€¢ **Audit Agent**: EC2, RDS, S3, Lambda resource discovery
â€¢ **Compliance Agent**: Policy violation detection using Amazon Bedrock
â€¢ **Policy Agent**: Automated remediation and enforcement

**Last Scan Results**: 156 resources monitored, 75% compliance score

Would you like me to start a new compliance scan?"""
    
    elif "policy" in prompt or "enforce" in prompt:
        return """âš™ï¸ **Dynamic Policy Enforcement:**

I can help you create and enforce policies across multiple frameworks:

â€¢ **GDPR**: Data protection and privacy
â€¢ **FISMA**: Federal security requirements  
â€¢ **EU AI Act**: AI system governance
â€¢ **ISO 42001**: AI management standards

**Auto-remediation** is available for common violations like encryption, access controls, and backup policies.

Which framework would you like to focus on?"""
    
    elif "report" in prompt:
        return """ğŸ“Š **Compliance Reporting:**

I can generate comprehensive reports including:

â€¢ **Executive Summary**: High-level compliance overview
â€¢ **Detailed Analysis**: Resource-by-resource breakdown
â€¢ **Violation Reports**: Priority remediation actions
â€¢ **Trend Analysis**: Compliance score over time

**Current Metrics**: 75% overall compliance, 3 critical violations

Would you like me to generate a specific report type?"""
    
    else:
        return """ğŸ¤– **AI Assistant Capabilities:**

I'm here to help with your governance and compliance needs:

â€¢ **Real-time Scanning**: Multi-agent AWS resource analysis
â€¢ **Policy Management**: Create, enforce, and monitor compliance rules
â€¢ **Automated Remediation**: Fix violations automatically where possible
â€¢ **Compliance Reporting**: Generate executive and detailed reports
â€¢ **Framework Support**: GDPR, FISMA, EU AI Act, ISO 42001

What specific compliance challenge can I help you solve today?"""

def show_reports():
    st.header("ğŸ“Š AI-Generated Compliance Reports")
    st.markdown("*Powered by Amazon Bedrock for intelligent analysis*")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“‹ Generate New Report")
        
        report_type = st.selectbox("Report Type", [
            "Executive Summary",
            "Detailed Compliance Analysis", 
            "Violation Remediation Plan",
            "Framework Comparison",
            "Trend Analysis"
        ])
        
        frameworks = st.multiselect(
            "Include Frameworks",
            list(COMPLIANCE_FRAMEWORKS.keys()),
            default=["GDPR", "FISMA"]
        )
        
        if st.button("ğŸš€ Generate AI Report", type="primary", use_container_width=True):
            with st.spinner("ğŸ¤– AI generating comprehensive report..."):
                time.sleep(2)
            
            st.success("âœ… Report generated successfully!")
            
            # Display generated report
            st.subheader("ğŸ“„ Generated Report")
            
            report_content = f"""
## ğŸ›¡ï¸ EnforceAI Compliance Report
**Generated**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**Type**: {report_type}
**Frameworks**: {', '.join(frameworks)}

### ğŸ“Š Executive Summary
- **Overall Compliance Score**: 75%
- **Resources Monitored**: 156
- **Critical Violations**: 3
- **Auto-remediated Issues**: 8

### ğŸ¯ Key Findings
1. **GDPR Compliance**: 72% - Encryption gaps identified
2. **FISMA Compliance**: 68% - Access control improvements needed  
3. **EU AI Act**: 85% - Documentation updates required
4. **ISO 42001**: 90% - Strong governance framework

### âš¡ Priority Actions
1. **Enable encryption** on 4 RDS databases (GDPR)
2. **Configure MFA** for 12 EC2 instances (FISMA)
3. **Update AI documentation** for 3 ML models (EU AI Act)
4. **Implement backup policies** for critical S3 buckets

### ğŸ“ˆ Compliance Trends
- **30-day improvement**: +5% overall compliance
- **Auto-remediation success**: 89%
- **Policy enforcement**: 156 resources monitored continuously

### ğŸ”§ Recommended Next Steps
1. Run auto-remediation for encryption violations
2. Schedule weekly compliance scans
3. Implement real-time policy enforcement
4. Set up automated compliance reporting

---
*Report generated by EnforceAI Multi-Agent Governance System*
            """
            
            st.markdown(report_content)
    
    with col2:
        st.subheader("ğŸ“ˆ Report History")
        
        reports = [
            {"Date": "2024-01-15", "Type": "Executive", "Score": "75%", "Status": "âœ…"},
            {"Date": "2024-01-14", "Type": "Detailed", "Score": "73%", "Status": "âœ…"},
            {"Date": "2024-01-13", "Type": "Violation", "Score": "71%", "Status": "âœ…"},
            {"Date": "2024-01-12", "Type": "Trend", "Score": "69%", "Status": "âœ…"}
        ]
        
        for report in reports:
            st.write(f"{report['Status']} **{report['Date']}**")
            st.write(f"   {report['Type']} Report - {report['Score']}")
            st.write("")
        
        st.subheader("ğŸ“¤ Export Options")
        col_a, col_b = st.columns(2)
        with col_a:
            st.button("ğŸ“„ PDF", use_container_width=True)
            st.button("ğŸ“§ Email", use_container_width=True)
        with col_b:
            st.button("â˜ï¸ S3", use_container_width=True)
            st.button("ğŸ“Š Excel", use_container_width=True)

if __name__ == "__main__":
    main()